{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys \n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/himani/memory_augmented_neural_net\"))\n",
    "from utils import OmniglotDataLoader, one_hot_decode, five_hot_decode\n",
    "#from model import NTMOneShotLearningModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class flags:\n",
    "    mode='train'\n",
    "    restore_training=False\n",
    "    debug=False\n",
    "    label_type='one_hot'\n",
    "    n_classes=3\n",
    "    seq_length=n_classes*10\n",
    "    augment=True\n",
    "    model='MANN'\n",
    "    read_head_num=4\n",
    "    batch_size=2\n",
    "    num_epoches=100000\n",
    "    learning_rate=1e-3\n",
    "    rnn_size=200\n",
    "    image_width=20\n",
    "    image_height=20\n",
    "    rnn_num_layers=1\n",
    "    memory_size=128\n",
    "    memory_vector_dim=40\n",
    "    test_batch_num=100\n",
    "    n_train_classes=1200\n",
    "    n_test_classes=423\n",
    "    save_dir='/home/himani/checkpoints/run1'\n",
    "    tensorboard_dir='/home/himani/logs/run1'\n",
    "    test_frequency=2\n",
    "    save_frequency=5000\n",
    "\n",
    "args=flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloading complete...\n"
     ]
    }
   ],
   "source": [
    "data_loader = OmniglotDataLoader(\n",
    "    image_size=(args.image_width, args.image_height),\n",
    "    n_train_classses=args.n_train_classes,\n",
    "    n_test_classes=args.n_test_classes)\n",
    "print(\"Dataloading complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model with default settings: \n",
    "* label_type: one_hot\n",
    "* model: MANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MANNCell():\n",
    "    def __init__(self, rnn_size, memory_size, memory_vector_dim, head_num, gamma=0.95,\n",
    "                 reuse=False, k_strategy='separate'):\n",
    "        self.rnn_size = rnn_size\n",
    "        self.memory_size = memory_size\n",
    "        self.memory_vector_dim = memory_vector_dim\n",
    "        self.head_num = head_num                                    # #(read head) == #(write head)\n",
    "        self.reuse = reuse\n",
    "        self.controller = tf.nn.rnn_cell.BasicLSTMCell(self.rnn_size)\n",
    "        self.step = 0\n",
    "        self.gamma = gamma\n",
    "        self.k_strategy = k_strategy\n",
    "\n",
    "    def __call__(self, x, prev_state):\n",
    "        prev_read_vector_list = prev_state['read_vector_list']      # read vector (the content that is read out, length = memory_vector_dim)\n",
    "        prev_controller_state = prev_state['controller_state']      # state of controller (LSTM hidden state)\n",
    "\n",
    "        # x + prev_read_vector -> controller (RNN) -> controller_output\n",
    "\n",
    "        controller_input = tf.concat([x] + prev_read_vector_list, axis=1)\n",
    "        with tf.variable_scope('controller', reuse=self.reuse):\n",
    "            controller_output, controller_state = self.controller(controller_input, prev_controller_state)\n",
    "\n",
    "        # controller_output (after fully connected layer): \n",
    "        #                       -> k (dim = memory_vector_dim, compared to each vector in M)\n",
    "        #                       -> a (dim = memory_vector_dim, add vector, only when k_strategy='separate')\n",
    "        #                       -> alpha (scalar, combination of w_r and w_lu)\n",
    "\n",
    "        if self.k_strategy == 'summary':\n",
    "            num_parameters_per_head = self.memory_vector_dim + 1\n",
    "        elif self.k_strategy == 'separate':\n",
    "            num_parameters_per_head = self.memory_vector_dim * 2 + 1\n",
    "        total_parameter_num = num_parameters_per_head * self.head_num\n",
    "        \n",
    "        with tf.variable_scope(\"o2p\", reuse=(self.step > 0) or self.reuse):\n",
    "            o2p_w = tf.get_variable('o2p_w', [controller_output.get_shape()[1], total_parameter_num],\n",
    "                                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "            o2p_b = tf.get_variable('o2p_b', [total_parameter_num],\n",
    "                                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "            parameters = tf.nn.xw_plus_b(controller_output, o2p_w, o2p_b)\n",
    "        head_parameter_list = tf.split(parameters, self.head_num, axis=1) #k,a,alpha\n",
    "\n",
    "        # k, prev_M -> w_r\n",
    "        # alpha, prev_w_r, prev_w_lu -> w_w\n",
    "\n",
    "        prev_w_r_list = prev_state['w_r_list']      # vector of weightings (blurred address) over locations\n",
    "        prev_M = prev_state['M']\n",
    "        prev_w_u = prev_state['w_u']\n",
    "        prev_indices, prev_w_lu = self.least_used(prev_w_u)\n",
    "        w_r_list = []\n",
    "        w_w_list = []\n",
    "        k_list = []\n",
    "        a_list = []\n",
    "        # p_list = []   # For debugging\n",
    "        for i, head_parameter in enumerate(head_parameter_list):\n",
    "            with tf.variable_scope('addressing_head_%d' % i):\n",
    "                k = tf.tanh(head_parameter[:, 0:self.memory_vector_dim], name='k')\n",
    "                if self.k_strategy == 'separate':\n",
    "                    a = tf.tanh(head_parameter[:, self.memory_vector_dim:self.memory_vector_dim * 2], name='a')\n",
    "                sig_alpha = tf.sigmoid(head_parameter[:, -1:], name='sig_alpha')\n",
    "                w_r = self.read_head_addressing(k, prev_M)\n",
    "                w_w = self.write_head_addressing(sig_alpha, prev_w_r_list[i], prev_w_lu)\n",
    "            w_r_list.append(w_r)\n",
    "            w_w_list.append(w_w)\n",
    "            k_list.append(k)\n",
    "            if self.k_strategy == 'separate':\n",
    "                a_list.append(a)\n",
    "            # p_list.append({'k': k, 'sig_alpha': sig_alpha, 'a': a})   # For debugging\n",
    "\n",
    "        w_u = self.gamma * prev_w_u + tf.add_n(w_r_list) + tf.add_n(w_w_list)   # eq (20)\n",
    "\n",
    "        # Set least used memory location computed from w_(t-1)^u to zero\n",
    "        M_ = prev_M * tf.expand_dims(1. - tf.one_hot(prev_indices[:, -1], self.memory_size), dim=2)\n",
    "\n",
    "        # Writing\n",
    "        M = M_\n",
    "        with tf.variable_scope('writing'):\n",
    "            for i in range(self.head_num):\n",
    "                w = tf.expand_dims(w_w_list[i], axis=2)\n",
    "                if self.k_strategy == 'summary':\n",
    "                    k = tf.expand_dims(k_list[i], axis=1)\n",
    "                elif self.k_strategy == 'separate':\n",
    "                    k = tf.expand_dims(a_list[i], axis=1)\n",
    "                M = M + tf.matmul(w, k)\n",
    "\n",
    "        # Reading\n",
    "        read_vector_list = []\n",
    "        with tf.variable_scope('reading'):\n",
    "            for i in range(self.head_num):\n",
    "                read_vector = tf.reduce_sum(tf.expand_dims(w_r_list[i], dim=2) * M, axis=1)\n",
    "                read_vector_list.append(read_vector)\n",
    "\n",
    "        # controller_output -> NTM output\n",
    "        NTM_output = tf.concat([controller_output] + read_vector_list, axis=1)\n",
    "\n",
    "        state = {\n",
    "            'controller_state': controller_state,\n",
    "            'read_vector_list': read_vector_list,\n",
    "            'w_r_list': w_r_list,\n",
    "            'w_w_list': w_w_list,\n",
    "            'w_u': w_u,\n",
    "            'M': M,\n",
    "        }\n",
    "\n",
    "        self.step += 1\n",
    "        return NTM_output, state\n",
    "\n",
    "    def read_head_addressing(self, k, prev_M):\n",
    "        with tf.variable_scope('read_head_addressing'):\n",
    "\n",
    "            # Cosine Similarity\n",
    "\n",
    "            k = tf.expand_dims(k, axis=2)\n",
    "            inner_product = tf.matmul(prev_M, k)\n",
    "            k_norm = tf.sqrt(tf.reduce_sum(tf.square(k), axis=1, keep_dims=True))\n",
    "            M_norm = tf.sqrt(tf.reduce_sum(tf.square(prev_M), axis=2, keep_dims=True))\n",
    "            norm_product = M_norm * k_norm\n",
    "            K = tf.squeeze(inner_product / (norm_product + 1e-8))                   # eq (17)\n",
    "\n",
    "            # Calculating w^c\n",
    "\n",
    "            K_exp = tf.exp(K)\n",
    "            w = K_exp / tf.reduce_sum(K_exp, axis=1, keep_dims=True)                # eq (18)\n",
    "\n",
    "            return w\n",
    "\n",
    "    def write_head_addressing(self, sig_alpha, prev_w_r, prev_w_lu):\n",
    "        with tf.variable_scope('write_head_addressing'):\n",
    "\n",
    "            # Write to (1) the place that was read in t-1 (2) the place that was least used in t-1\n",
    "\n",
    "            return sig_alpha * prev_w_r + (1. - sig_alpha) * prev_w_lu              # eq (22)\n",
    "\n",
    "    def least_used(self, w_u):\n",
    "        _, indices = tf.nn.top_k(w_u, k=self.memory_size)\n",
    "        w_lu = tf.reduce_sum(tf.one_hot(indices[:, -self.head_num:], depth=self.memory_size), axis=1)\n",
    "        return indices, w_lu\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        one_hot_weight_vector = np.zeros([batch_size, self.memory_size])\n",
    "        one_hot_weight_vector[..., 0] = 1\n",
    "        one_hot_weight_vector = tf.constant(one_hot_weight_vector, dtype=tf.float32)\n",
    "        with tf.variable_scope('init', reuse=self.reuse):\n",
    "            state = {\n",
    "                'controller_state': self.controller.zero_state(batch_size, dtype),\n",
    "                'read_vector_list': [tf.zeros([batch_size, self.memory_vector_dim])\n",
    "                                     for _ in range(self.head_num)],\n",
    "                'w_r_list': [one_hot_weight_vector for _ in range(self.head_num)],\n",
    "                'w_u': one_hot_weight_vector,\n",
    "                'M': tf.constant(np.ones([batch_size, self.memory_size, self.memory_vector_dim]) * 1e-6, dtype=tf.float32)\n",
    "            }\n",
    "            return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NTMOneShotLearningModel():\n",
    "    def __init__(self, args):\n",
    "        args.output_dim = args.n_classes\n",
    "        \n",
    "        #placeholders for inputs\n",
    "        self.x_image = tf.placeholder(dtype=tf.float32,\n",
    "                                      shape=[args.batch_size, args.seq_length, args.image_width * args.image_height])\n",
    "        self.x_label = tf.placeholder(dtype=tf.float32,\n",
    "                                      shape=[args.batch_size, args.seq_length, args.output_dim])\n",
    "        self.y = tf.placeholder(dtype=tf.float32,\n",
    "                                shape=[args.batch_size, args.seq_length, args.output_dim])\n",
    "        \n",
    "        #create cell\n",
    "        self.cell = MANNCell(args.rnn_size, args.memory_size, args.memory_vector_dim,\n",
    "                                    head_num=args.read_head_num)\n",
    "        \n",
    "        #step over the entire episode\n",
    "        state = self.cell.zero_state(args.batch_size, tf.float32)\n",
    "        self.state_list = [state]   # For debugging\n",
    "        self.o = []\n",
    "        for t in range(args.seq_length):\n",
    "            output, state = self.cell(tf.concat([self.x_image[:, t, :], self.x_label[:, t, :]], axis=1), state)\n",
    "            # output, state = self.cell(self.y[:, t, :], state)\n",
    "            with tf.variable_scope(\"o2o\", reuse=(t > 0)):\n",
    "                o2o_w = tf.get_variable('o2o_w', [output.get_shape()[1], args.output_dim],\n",
    "                                        initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "                o2o_b = tf.get_variable('o2o_b', [args.output_dim],\n",
    "                                        initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "                output = tf.nn.xw_plus_b(output, o2o_w, o2o_b)\n",
    "            \n",
    "            output = tf.nn.softmax(output, dim=1)\n",
    "\n",
    "            self.o.append(output)\n",
    "            self.state_list.append(state)\n",
    "            \n",
    "        self.o = tf.stack(self.o, axis=1)\n",
    "        self.state_list.append(state)\n",
    "\n",
    "        eps = 1e-8\n",
    "        self.learning_loss = -tf.reduce_mean(  # cross entropy function\n",
    "            tf.reduce_sum(self.y * tf.log(self.o + eps), axis=[1, 2])\n",
    "        )\n",
    "\n",
    "        self.o = tf.reshape(self.o, shape=[args.batch_size, args.seq_length, -1])\n",
    "\n",
    "        with tf.variable_scope('optimizer'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=args.learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(self.learning_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing model...\")\n",
    "model = NTMOneShotLearningModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.Session(config=config)\n",
    "\n",
    "if args.restore_training:\n",
    "    saver = tf.train.Saver(max_to_keep=2)\n",
    "    ckpt = tf.train.get_checkpoint_state(args.save_dir + '/' + args.model)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    saver = tf.train.Saver(tf.global_variables(),max_to_keep=2)\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##assumption, min seq_length is 11\n",
    "\n",
    "def test_f(args, y, output):\n",
    "    correct = [0] * args.seq_length\n",
    "    total = [0] * args.seq_length\n",
    "    if args.label_type == 'one_hot':\n",
    "        y_decode = one_hot_decode(y)\n",
    "        output_decode = one_hot_decode(output)\n",
    "    elif args.label_type == 'five_hot':\n",
    "        y_decode = five_hot_decode(y)\n",
    "        output_decode = five_hot_decode(output)\n",
    "    for i in range(np.shape(y)[0]):\n",
    "        y_i = y_decode[i]\n",
    "        output_i = output_decode[i]\n",
    "        # print(y_i)\n",
    "        # print(output_i)\n",
    "        class_count = {}\n",
    "        for j in range(args.seq_length):\n",
    "            if y_i[j] not in class_count:\n",
    "                class_count[y_i[j]] = 0\n",
    "            class_count[y_i[j]] += 1\n",
    "            total[class_count[y_i[j]]] += 1\n",
    "            if y_i[j] == output_i[j]:\n",
    "                correct[class_count[y_i[j]]] += 1\n",
    "    return [float(correct[i]) / total[i] if total[i] > 0. else 0. for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args.num_epoches=1 #args.num_epoches\n",
    "args.test_frequency=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\tloss\t1st\t2nd\t3rd\t4th\t5th\t6th\t7th\t8th\t9th\t10th\n",
      "0\t33.0854\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t0.3333\t\n"
     ]
    }
   ],
   "source": [
    "print(\"batch\\tloss\\t1st\\t2nd\\t3rd\\t4th\\t5th\\t6th\\t7th\\t8th\\t9th\\t10th\")\n",
    "\n",
    "\n",
    "for b in range(args.num_epoches):\n",
    "    # Test\n",
    "    if b % args.test_frequency == 0:\n",
    "        x_image, x_label, y = data_loader.fetch_batch(\n",
    "            args.n_classes, args.batch_size, args.seq_length,\n",
    "            type='test',augment=args.augment,label_type=args.label_type)\n",
    "        \n",
    "        feed_dict = {model.x_image: x_image, \n",
    "                     model.x_label: x_label, \n",
    "                     model.y: y}\n",
    "        \n",
    "        output, learning_loss = sess.run([model.o, model.learning_loss], feed_dict=feed_dict)\n",
    "\n",
    "        print('%d\\t%.4f\\t' % (b, learning_loss)),\n",
    "        accuracy = test_f(args, y, output)\n",
    "        for accu in accuracy:\n",
    "            print('%.4f\\t' % accu),\n",
    "        print('')\n",
    "        \n",
    "    if b % args.save_frequency == 0 and b > 0:\n",
    "        saver.save(sess, args.save_dir + '/' + args.model + '/model.tfmodel', global_step=b)\n",
    "    \n",
    "    # Train\n",
    "    x_image, x_label, y = data_loader.fetch_batch(\n",
    "        args.n_classes, args.batch_size, args.seq_length,\n",
    "        type='train',augment=args.augment,label_type=args.label_type)\n",
    "    \n",
    "    feed_dict = {model.x_image: x_image, \n",
    "                 model.x_label: x_label, \n",
    "                 model.y: y}\n",
    "    \n",
    "    sess.run(model.train_op, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image, x_label, y = data_loader.fetch_batch(\n",
    "    args.n_classes, args.batch_size, args.seq_length,\n",
    "    type='train',augment=args.augment,label_type=args.label_type)\n",
    "\n",
    "feed_dict = {model.x_image: x_image, \n",
    "             model.x_label: x_label, \n",
    "             model.y: y}\n",
    "\n",
    "eval_outputs=[model.state_list,\n",
    "             model.o]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "30\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_image)) #batch-size\n",
    "print(len(x_image[0])) #episode_length\n",
    "print(x_image[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out=sess.run(eval_outputs, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_list=out[0]\n",
    "o=out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "5\n",
      "['w_u', 'read_vector_list', 'controller_state', 'M', 'w_r_list']\n"
     ]
    }
   ],
   "source": [
    "print(len(state_list))\n",
    "print(len(state_list[0]))\n",
    "print(state_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128)\n"
     ]
    }
   ],
   "source": [
    "print(state_list[0]['w_u'].shape) #batch_size, mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(2, 40)\n"
     ]
    }
   ],
   "source": [
    "print(len(state_list[0]['read_vector_list'])) #num_read_heads\n",
    "print(state_list[0]['read_vector_list'][0].shape) #batch_size, mem_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>\n",
      "2\n",
      "(2, 200)\n",
      "LSTMStateTuple(c=200, h=200)\n"
     ]
    }
   ],
   "source": [
    "print(type(state_list[0]['controller_state']))# 2-tuples of the c_state and m_state\n",
    "print(len(state_list[0]['controller_state'])) \n",
    "print(state_list[0]['controller_state'][0].shape) #batch_size,rnn_size\n",
    "\n",
    "print(model.cell.controller.state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 128, 40)\n"
     ]
    }
   ],
   "source": [
    "print(state_list[0]['M'].shape) #batch_size,mem_size,mem_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(2, 128)\n"
     ]
    }
   ],
   "source": [
    "print(len(state_list[0]['w_r_list'])) #num_read_heads\n",
    "print(state_list[0]['w_r_list'][0].shape) #batch_size, mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=200, h=200)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating w_l_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "wu=state_list[0]['w_u']\n",
    "print(wu[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25650661  0.20915602  0.29043392  0.34055697  0.87345325]\n",
      " [ 0.18170077  0.44975874  0.93630793  0.37495192  0.51294125]]\n"
     ]
    }
   ],
   "source": [
    "bb=np.random.rand(10)\n",
    "bb=np.reshape(bb,(2,-1))\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals, indices = tf.nn.top_k(bb, k=5)\n",
    "inds2=indices[:, -2:]\n",
    "tmp=tf.one_hot(inds2,depth=5)\n",
    "bb2= tf.reduce_sum(tmp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.87345325,  0.34055697,  0.29043392,  0.25650661,  0.20915602],\n",
       "        [ 0.93630793,  0.51294125,  0.44975874,  0.37495192,  0.18170077]]),\n",
       " array([[4, 3, 2, 0, 1],\n",
       "        [2, 4, 1, 3, 0]], dtype=int32),\n",
       " array([[0, 1],\n",
       "        [3, 0]], dtype=int32),\n",
       " array([[[ 1.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0.,  1.,  0.],\n",
       "         [ 1.,  0.,  0.,  0.,  0.]]], dtype=float32),\n",
       " array([[ 1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  1.,  0.]], dtype=float32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([vals,indices,inds2,tmp,bb2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "wr=state_list[0]['w_r_list']\n",
    "print(wr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8994863   0.11661608  0.48097275  0.99441174  0.42735952]\n",
      " [ 0.38328854  0.6363465   0.60420785  0.75010454  0.53011838]]\n",
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "bb=np.random.rand(10)\n",
    "bb=np.reshape(bb,(2,-1))\n",
    "print(bb)\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "mem=np.ones((5,3))\n",
    "print(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb2=tf.expand_dims(bb, dim=2)\n",
    "mul=bb2*mem\n",
    "bb3=tf.reduce_sum(mul,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b,c=sess.run([bb2,mul,bb3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.8994863 ]\n",
      "  [ 0.11661608]\n",
      "  [ 0.48097275]\n",
      "  [ 0.99441174]\n",
      "  [ 0.42735952]]\n",
      "\n",
      " [[ 0.38328854]\n",
      "  [ 0.6363465 ]\n",
      "  [ 0.60420785]\n",
      "  [ 0.75010454]\n",
      "  [ 0.53011838]]]\n",
      "2\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(len(a))\n",
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.8994863   0.8994863   0.8994863 ]\n",
      "  [ 0.11661608  0.11661608  0.11661608]\n",
      "  [ 0.48097275  0.48097275  0.48097275]\n",
      "  [ 0.99441174  0.99441174  0.99441174]\n",
      "  [ 0.42735952  0.42735952  0.42735952]]\n",
      "\n",
      " [[ 0.38328854  0.38328854  0.38328854]\n",
      "  [ 0.6363465   0.6363465   0.6363465 ]\n",
      "  [ 0.60420785  0.60420785  0.60420785]\n",
      "  [ 0.75010454  0.75010454  0.75010454]\n",
      "  [ 0.53011838  0.53011838  0.53011838]]]\n",
      "(2, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.91884639  2.91884639  2.91884639]\n",
      " [ 2.90406581  2.90406581  2.90406581]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over internal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image, x_label, y = data_loader.fetch_batch(\n",
    "    args.n_classes, args.batch_size, args.seq_length,\n",
    "    type='train',augment=args.augment,label_type=args.label_type)\n",
    "\n",
    "feed_dict = {model.x_image: x_image, \n",
    "             model.x_label: x_label, \n",
    "             model.y: y}\n",
    "\n",
    "eval_outputs=[model.state_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ******** step: 0 **********\n",
      "LSTMStateTuple(c=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32))\n",
      "\n",
      " ******** step: 1 **********\n",
      "LSTMStateTuple(c=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32))\n",
      "\n",
      " ******** step: 2 **********\n",
      "LSTMStateTuple(c=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "    out=sess.run(eval_outputs, feed_dict=feed_dict)\n",
    "    print('\\n ******** step: %d **********'%i)\n",
    "    print(out[0][0]['controller_state'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "env_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
